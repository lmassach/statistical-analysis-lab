{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "municipal-catch",
   "metadata": {},
   "source": [
    "2022-03-28 Ludovico Massaccesi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-wales",
   "metadata": {},
   "source": [
    "# Interval estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-casino",
   "metadata": {},
   "source": [
    "## Confidence Level\n",
    "$$CL(f)=\\inf_{\\mu\\in A}\\int_{x:f(x)\\ni\\mu}p(x;\\mu)$$\n",
    "where $x$ is the data, $\\mu$ are the parameters of the distribution, and the function $f(x)$ gives the interval based on the data.\n",
    "The _confidence level_ is a property of the algorithm $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-fetish",
   "metadata": {},
   "source": [
    "## Coverage\n",
    "This one is defined to make the confidence level easier to understand and compute.\n",
    "The coverage is\n",
    "$$C(\\mu)=\\int_{x:f(x)\\ni\\mu}p(x;\\mu)$$\n",
    "so that\n",
    "$$CL(f)=\\inf_{\\mu\\in A}C(\\mu)$$\n",
    "\n",
    "In practice we want $C(\\mu)=CL$.\n",
    "If we have $C(\\mu)>CL$ we are overcovering (making too-large intervals).\n",
    "If we have $C(\\mu)<CL$ we are undercovering, i.e. our algorithm does not obtain the required CL (it is _wrong!_)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-premiere",
   "metadata": {},
   "source": [
    "## Neyman's confidence band construction\n",
    "We look at the (possible) data $x$ as a function of the parameters $\\mu$.\n",
    "\n",
    " - For each value of $\\mu$, we compute the integral of the probability of $x$, $\\int p(x;\\mu)\\text dx$, which will be our coverage $C(\\mu)$.\n",
    " - For each value of $\\mu$, we choose a set of $x$ over which the integral is $CL$ (there are many possible ways to do this).\n",
    " - Then, we take the data and we swap the axes: our confidence region will be given by the intersection of the line $x=\\text{our data}$ with the intervals defined before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-elephant",
   "metadata": {},
   "source": [
    "### Ordering algorithms\n",
    "To choose the intervals, we usually define an _ordering function_ $o(x)$, so that we can build the band by requiring that\n",
    "$$\\int_{o(x)>c}p(x;\\mu)\\geq CL$$\n",
    "One usually does this by including the samples $x$ with larger $o(x)$ first, and then going to $x$ points with lower $o(x)$ values.\n",
    "\n",
    "There are many possible $o(x)$ to choose:\n",
    "\n",
    " - low/high $o(x)=\\pm x$, usually for upper/lower limits;\n",
    " - central $o(x)$ such that we take half of the $x$ samples to be excluded from below, and the other half from above (the $o(x)$ function can become very complicated in this case);\n",
    " - P-ordering $o(x)=p(x;\\mu)$ (fast to compute);\n",
    " - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-space",
   "metadata": {},
   "source": [
    "# Exercise: Poisson\n",
    "Not the Gaussian because it can all be done analytically and very easily.\n",
    "$$p(n;\\mu)=\\frac{e^{-\\mu}\\mu^n}{n!}$$\n",
    "Do it with all the four methods:\n",
    "\n",
    "1. lower limit $\\sum_{n=0}^{n_{max}(\\mu)}p(n;\\mu)\\geq CL$;\n",
    "2. upper limit $\\sum_{n=n_{min}(\\mu)}^\\infty p(n;\\mu)=1-\\sum_{n=0}^{n_{min}(\\mu)-1}p(n;\\mu)\\geq CL$;\n",
    "3. central $\\sum_{n=n_{max}(\\mu)+1}^\\infty p(n;\\mu)=1-\\sum_{n=0}^{n_{max}(\\mu)}p(n;\\mu)\\leq\\frac{1-CL}{2}$ and, separately, $\\sum_{n=0}^{n_{min}(\\mu)-1}p(n;\\mu)\\leq\\frac{1-CL}{2}$; and\n",
    "4. P-ordering $\\sum_{n:p(n;\\mu)>\\bar p}p(n;\\mu)\\geq CL$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-priest",
   "metadata": {},
   "source": [
    "# Bayesian interval estimation\n",
    "This method is based on the _posterior_:\n",
    "$$\\pi_x(\\mu)=\\pi(\\mu)\\frac{L_x(\\mu)}{p(x)}$$\n",
    "where $\\pi(\\mu)$ is the _prior_ \"probability\" of $\\mu$, $\\pi_x(\\mu)$ is the _posterior_ \"probability\" of $\\mu$, $p(x)$ is the probability of the data $x$, and $L_x(\\mu)$ is the likelihood of $\\mu$ given $x$ (in practice it is $p_\\mu(x)$, the probability of $x$ given $\\mu$).\n",
    "\n",
    "The interval is derived from the posterior:\n",
    "$$f(x)=\\phi:\\int_\\phi \\pi_x(\\mu)\\text d\\mu=c$$\n",
    "where $c$ is a constant value called _credibility_ or _credibility level_.\n",
    "This is more straightforward than the frequentist method, but it invloves credibilities / fake probabilities, and requires a prior.\n",
    "\n",
    "In order to choose $\\phi$ we can define an ordering, like before, but in the _parameters space_ instead of the _observations space_.\n",
    "The common choice is the _posterior ordering_, similar to the probability ordering mentioned before.\n",
    "\n",
    "Of course, like before, we could choose any $f$ we want.\n",
    "\n",
    "We can also define the credibility of our $f$, like we defined the CL before,\n",
    "$$Cr(x)=\\int_{\\mu\\in f(x)} \\pi_x(\\mu)\\text d\\mu$$\n",
    "Note that this is a function of the data $x$, not of the parameters $\\mu$ (everything is complementary in the Bayesian method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-traffic",
   "metadata": {},
   "source": [
    "# Exercise: Poisson but Bayesian\n",
    "Compute credible intervals using constant prior $\\pi(\\mu)=\\text{const}$ (this has infinite integral, must be taken into account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-leonard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
