{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defensive-lending",
   "metadata": {},
   "source": [
    "2022-04-11 Ludovico Massaccesi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-absorption",
   "metadata": {},
   "source": [
    "# Relating confidence and credibility\n",
    "They are two different things, but this relation holds\n",
    "$$E_x[Cr(x)] = \\int Cr(x)p(x)\\text dx = \\iint_{\\mu\\in f(x)} \\pi(\\mu|x)\\text d\\mu \\cdot p(x)\\text dx=$$\n",
    "$$\\iint_{\\mu\\in f(x)}\\frac{p(x|\\mu)\\pi(mu)}{p(x)}\\text d\\mu \\cdot p(x)\\text dx=\\int \\pi(\\mu)\\text d\\mu\\int_{f(x)\\ni\\mu}p(x|\\mu)\\text dx=$$\n",
    "$$=\\int C(\\mu)\\pi(\\mu)\\text d\\mu=E_\\mu[C(\\mu)]$$\n",
    "so the \"average confidence is equal to the average credibility\".\n",
    "Note that this equation does not make any sense from the frequentist point of view: it makes use of a prior, which is defined only in the Bayesian framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-assumption",
   "metadata": {},
   "source": [
    "Confidence limits can be set based on anything, even not of data: \"if I win the lottery, I conclude that donkeys can fly with 99.9999% CL\".\n",
    "Of course this is a stupid algorithm, but it is valid.\n",
    "\n",
    "It is actually rather easy to fall in this kind of mistake, and choosing a good ordering function is non-trivial: if I take the P-ordered Neyman band for a Gaussian, this is easy (it is the region between two parallel lines); but if I force the mean to be positive, that band does not work anymore, and I get undercoverage for low values of the observation, and no band for negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-event",
   "metadata": {},
   "source": [
    "## Feldman-Cousins' \"unified approach\"\n",
    "Use as ordering function the likelihood ratio\n",
    "$$LR(x)=\\frac{p(x|\\mu)}{\\sup_{\\mu'} p(x|\\mu')}$$\n",
    "of course, the maximum is taken over the valid interval that we chose.\n",
    "\n",
    "This approach naturally avoids empty intervals and flip-flopping; it is also invariant for change of observable.\n",
    "Still, it is _not_ perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-prior",
   "metadata": {},
   "source": [
    "## Simplification of confidence regions\n",
    "The computation can be simplified, especially with many dimensions, by using:\n",
    "\n",
    " - a sufficient statistic, if it exists;\n",
    " - a _pivotal quantity_, i.e. a function $s(x,\\mu)$ such that its probability is the same $\\forall\\mu$, $p(s(x,\\mu),\\mu)=p(s)$.\n",
    " \n",
    "Some pivotal quantities are very common, i.e. $s=(x-\\mu)/\\sigma$ when working with Gaussian variables.\n",
    "\n",
    "Sometimes one can find not an exact, but an asymptotical pivotal quantity, which gives an approximate CL region that is correct in the limit of large $n$.\n",
    "The log-LR is _almost_ always such a quantity (see Wilk's theorem)\n",
    "$$\\lambda(x,\\mu)=-2\\log\\frac{\\sup_{\\mu'} p(x|\\mu')}{p(x|\\mu)}$$\n",
    "and it is asymptotically distributed as a $\\chi^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-drink",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "Previous ones, with LR-ordering and log-LR (approximate by solving $\\lambda(n,\\mu)=3.84146\\dots$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-theme",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
